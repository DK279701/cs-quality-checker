import streamlit as st
import pandas as pd
import requests
import aiohttp
import asyncio
import time
from bs4 import BeautifulSoup

# --- Streamlit page config ---
st.set_page_config(page_title="CS Quality Checker", layout="wide")
st.title("üì• Pobieranie i analiza OUTBOUND wiadomo≈õci z Front")

# --- Sidebar: API keys ---
st.sidebar.header("üîë Klucze API")
front_token = st.sidebar.text_input("Front API Token", type="password")
openai_key  = st.sidebar.text_input("OpenAI API Key",   type="password")
if not front_token or not openai_key:
    st.sidebar.warning("Wprowad≈∫ oba klucze API (Front i OpenAI).")
    st.stop()

# --- Sta≈Çe inboxy ---
INBOX_IDS = ["inb_a3xxy", "inb_d2uom", "inb_d2xee"]
st.sidebar.markdown("**Wykorzystywane inboxy:**")
for iid in INBOX_IDS:
    st.sidebar.write(f"- `{iid}`")

# --- Pobierz dane konkretnego teammate'a i cache'uj ---
@st.cache_data(ttl=3600)
def get_teammate_info(token, teammate_id):
    url = f"https://api2.frontapp.com/teammates/{teammate_id}"
    headers = {"Authorization": f"Bearer {token}"}
    resp = requests.get(url, headers=headers)
    resp.raise_for_status()
    data = resp.json()
    return {
        "username":   data.get("username", ""),
        "first_name": data.get("first_name", ""),
        "last_name":  data.get("last_name", "")
    }

# --- Funkcja pobierajƒÖca i filtrujƒÖca tylko outbound ---
@st.cache_data(ttl=300)
def fetch_outbound_messages(token, inbox_ids):
    headers = {"Authorization": f"Bearer {token}", "Accept": "application/json"}
    base_url = "https://api2.frontapp.com/conversations"
    records = []
    teammate_ids = set()

    for inbox in inbox_ids:
        params = {"inbox_id": inbox, "page_size": 100}
        while True:
            r = requests.get(base_url, headers=headers, params=params)
            r.raise_for_status()
            js = r.json()
            for conv in js.get("_results", []):
                cid = conv["id"]
                r2 = requests.get(f"{base_url}/{cid}/messages", headers=headers)
                r2.raise_for_status()
                for m in r2.json().get("_results", []):
                    if m.get("is_inbound", True):
                        continue
                    raw_body = m.get("body", "")
                    text = BeautifulSoup(raw_body, "html.parser").get_text(separator="\n")
                    raw_author = m.get("author", {})
                    if isinstance(raw_author, dict) and raw_author.get("id", "").startswith("tea_"):
                        tid = raw_author["id"]
                        teammate_ids.add(tid)
                        author_ref = tid
                    else:
                        author_ref = (raw_author.get("handle") if isinstance(raw_author, dict)
                                      else str(raw_author) if raw_author else "Unknown")
                    records.append({
                        "Inbox ID":        inbox,
                        "Conversation ID": cid,
                        "Message ID":      m.get("id", ""),
                        "__author_ref":    author_ref,
                        "Extract":         text
                    })
            cursor = js.get("_cursor")
            if not cursor:
                break
            params["cursor"] = cursor

    teammates = {tid: get_teammate_info(token, tid) for tid in teammate_ids}

    df = pd.DataFrame(records)
    def resolve_author(ref):
        if isinstance(ref, str) and ref.startswith("tea_"):
            info = teammates.get(ref, {})
            return f"{info.get('first_name','')} {info.get('last_name','')} ({info.get('username','')})"
        return ref or "Unknown"
    df["Author"] = df["__author_ref"].map(resolve_author)
    df.drop(columns="__author_ref", inplace=True)
    return df

# --- G≈Ç√≥wny flow aplikacji ---
if st.button("‚ñ∂Ô∏è Pobierz i analizuj OUTBOUND wiadomo≈õci"):
    with st.spinner("‚è≥ Pobieranie wiadomo≈õci‚Ä¶"):
        df = fetch_outbound_messages(front_token, INBOX_IDS)

    if df.empty:
        st.warning("‚ùó Nie znaleziono ≈ºadnych wiadomo≈õci outbound.")
        st.stop()

    # --- Wyb√≥r autor√≥w do wykluczenia ---
    st.sidebar.header("üö´ Wyklucz autor√≥w")
    all_authors = sorted(df["Author"].unique())
    exclude = st.sidebar.multiselect("Wybierz autor√≥w do wykluczenia", all_authors)
    if exclude:
        df = df[~df["Author"].isin(exclude)]
        st.info(f"Wykluczono {len(exclude)} autor√≥w, pozosta≈Ço {len(df)} wiadomo≈õci.")

    if df.empty:
        st.warning("‚ùó Po wykluczeniu autor√≥w nie pozosta≈Çy ≈ºadne wiadomo≈õci.")
        st.stop()

    st.success(f"Pobrano i przygotowano do analizy {len(df)} wiadomo≈õci.")
    st.dataframe(df.head(10))

    # --- Async GPT analysis ---
    API_URL = "https://api.openai.com/v1/chat/completions"
    HEADERS  = {"Authorization": f"Bearer {openai_key}", "Content-Type": "application/json"}
    SYSTEM_PROMPT = (
        "Jeste≈õ Mened≈ºerem Customer Service w Bookinghost i oceniasz jako≈õƒá wiadomo≈õci agent√≥w "
        "w skali 1‚Äì5. We≈∫ pod uwagƒô:\n"
        "‚Ä¢ empatiƒô i uprzejmo≈õƒá\n"
        "‚Ä¢ poprawno≈õƒá jƒôzykowƒÖ\n"
        "‚Ä¢ zgodno≈õƒá z procedurami\n"
        "‚Ä¢ ton komunikacji\n\n"
        "Odpowiedz w formacie:\n"
        "Ocena: X/5\n"
        "Uzasadnienie: ‚Ä¢ punkt 1\n‚Ä¢ punkt 2"
    )

    async def analyze_one(session, rec):
        payload = {
            "model": "gpt-3.5-turbo",
            "messages": [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user",   "content": rec["Extract"]}
            ],
            "temperature": 0.3,
            "max_tokens": 200
        }
        try:
            async with session.post(API_URL, headers=HEADERS, json=payload) as resp:
                js = await resp.json()
        except Exception as e:
            return f"‚ùå Network/API error: {e}"
        if "error" in js:
            return f"‚ùå API error: {js['error'].get('message','Unknown')}"
        choices = js.get("choices")
        if not choices or not isinstance(choices, list):
            return "‚ùå Unexpected response format: missing 'choices'"
        content = choices[0].get("message", {}).get("content")
        if content is None:
            return "‚ùå Unexpected response format: missing 'message.content'"
        return content.strip()

    async def run_all(recs, progress, status):
        out = []
        batch = 20
        async with aiohttp.ClientSession() as sess:
            for i in range(0, len(recs), batch):
                chunk = recs[i : i + batch]
                res   = await asyncio.gather(*[analyze_one(sess, r) for r in chunk])
                out.extend(res)
                done = min(i + batch, len(recs))
                progress.progress(done / len(recs))
                status.text(f"Przetworzono: {done}/{len(recs)}")
        return out

    recs     = df.to_dict(orient="records")
    progress = st.progress(0.0)
    status   = st.empty()
    start    = time.time()
    with st.spinner("‚öôÔ∏è Analiza‚Ä¶"):
        df["Feedback"] = asyncio.run(run_all(recs, progress, status))
    st.success(f"‚úÖ Analiza zako≈Ñczona w {time.time() - start:.1f}s")

    # --- Parsowanie ocen ---
    def parse_score(txt):
        for l in txt.splitlines():
            if l.lower().startswith("ocena"):
                try:
                    return float(l.split(":")[1].split("/")[0].strip())
                except:
                    pass
        return None
    df["Score"] = df["Feedback"].map(parse_score)

    # --- Raport ---
    st.header("üìà Podsumowanie zespo≈Çu")
    st.metric("≈örednia ocena", f"{df['Score'].mean():.2f}/5")
    st.metric("Liczba analizowanych wiadomo≈õci", len(df))

    st.header("üë§ Raport agent√≥w")
    agg = (
        df.groupby("Author")
          .agg(≈örednia_ocena=("Score", "mean"), Liczba=("Score", "count"))
          .round(2)
          .reset_index()
    )
    st.dataframe(agg, use_container_width=True)

    st.header("üì• Pobierz pe≈Çen raport CSV")
    csv = df.to_csv(index=False, sep=";").encode("utf-8")
    st.download_button("‚¨áÔ∏è Pobierz CSV", data=csv, file_name="outbound_report.csv", mime="text/csv")
